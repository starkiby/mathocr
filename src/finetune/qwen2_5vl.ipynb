{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Â≠¶ÊúØÂä†ÈÄü\n",
    "\n",
    "Â¶ÇÊûúÊòØÂú® AutoDL ÁßüÁöÑÊúçÂä°Âô®Ôºå‰∏ãËΩΩÊ®°ÂûãÂâçËøêË°å‰∏ãÈù¢ cell ‰ª•Ëé∑ÂèñÂ≠¶ÊúØÂä†ÈÄü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 20 23:29:09 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L20                     On  |   00000000:71:01.0 Off |                  Off |\n",
      "| N/A   39C    P8             36W /  350W |       0MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Êü•Áúã GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qwen2.5-VL-finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "MAX_LENGTH = 8192\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id_3b = 'Qwen/Qwen2.5-VL-3B-Instruct-AWQ'\n",
    "model_id_7b = 'Qwen/Qwen2.5-VL-7B-Instruct-AWQ'\n",
    "save_dir_3b = './model/base/vl3b/'  # change to your save path\n",
    "save_dir_7b = './model/base/vl7b/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:834: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3a24a81dac40fb8473d9208437d1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a483ea8a8e1444848b5a8afd88958756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:  70%|######9   | 2.06G/2.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4700529ae854187b41aa7a1b6cc123f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:  59%|#####8    | 2.35G/3.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/root/autodl-tmp/HOCR/finetune/model/base/vl7b'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# snapshot_download(repo_id='Qwen/Qwen2.5-VL-3B-Instruct-AWQ', local_dir='./vl3b/', local_dir_use_symlinks=False)\n",
    "snapshot_download(repo_id=model_id_7b, local_dir=save_dir_7b, local_dir_use_symlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491bf64897cd4816b222d553f16395f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor, AutoTokenizer\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "\n",
    "model_7b = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    save_dir_7b, torch_dtype=torch.float16, \n",
    "    attn_implementation=\"flash_attention_2\", device_map='auto',\n",
    ")\n",
    "model_7b.to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_dir_7b)\n",
    "processor = AutoProcessor.from_pretrained(save_dir_7b)\n",
    "\n",
    "model_7b.enable_input_require_grads()   # ÂºÄÂêØÊ¢ØÂ∫¶Ê£ÄÊü•ÁÇπÊó∂(training_args.gradient_checkpointing=True,)Ë¶ÅÊâßË°åËØ•ÊñπÊ≥ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2_5_VLForConditionalGeneration(\n",
      "  (visual): Qwen2_5_VisionTransformerPretrainedModel(\n",
      "    (patch_embed): Qwen2_5_VisionPatchEmbed(\n",
      "      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
      "    )\n",
      "    (rotary_pos_emb): Qwen2_5_VisionRotaryEmbedding()\n",
      "    (blocks): ModuleList(\n",
      "      (0-31): 32 x Qwen2_5_VLVisionBlock(\n",
      "        (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "        (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "        (attn): Qwen2_5_VLVisionFlashAttention2(\n",
      "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
      "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "        (mlp): Qwen2_5_VLMLP(\n",
      "          (gate_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
      "          (up_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
      "          (down_proj): Linear(in_features=3420, out_features=1280, bias=True)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (merger): Qwen2_5_VLPatchMerger(\n",
      "      (ln_q): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Linear(in_features=5120, out_features=3584, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model): Qwen2_5_VLModel(\n",
      "    (embed_tokens): Embedding(152064, 3584)\n",
      "    (layers): ModuleList(\n",
      "      (0-27): 28 x Qwen2_5_VLDecoderLayer(\n",
      "        (self_attn): Qwen2_5_VLFlashAttention2(\n",
      "          (q_proj): WQLinear_GEMM(in_features=3584, out_features=3584, bias=True, w_bit=4, group_size=128)\n",
      "          (k_proj): WQLinear_GEMM(in_features=3584, out_features=512, bias=True, w_bit=4, group_size=128)\n",
      "          (v_proj): WQLinear_GEMM(in_features=3584, out_features=512, bias=True, w_bit=4, group_size=128)\n",
      "          (o_proj): WQLinear_GEMM(in_features=3584, out_features=3584, bias=False, w_bit=4, group_size=128)\n",
      "          (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): WQLinear_GEMM(in_features=3584, out_features=18944, bias=False, w_bit=4, group_size=128)\n",
      "          (up_proj): WQLinear_GEMM(in_features=3584, out_features=18944, bias=False, w_bit=4, group_size=128)\n",
      "          (down_proj): WQLinear_GEMM(in_features=18944, out_features=3584, bias=False, w_bit=4, group_size=128)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_7b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Êï∞ÊçÆÈõÜÂä†ËΩΩ„ÄÅÂàíÂàÜ„ÄÅÊò†Â∞Ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_func(example):\n",
    "    # print(f'example.ids: {example,keys()}'\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    url = example[\"message\"][0][\"conversation\"][0]['url']\n",
    "    caption = example[\"message\"][0][\"conversation\"][1]['caption']\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant in recognize math equations in either handwritten or printed text.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\", \"text\": \"Recognize the equation in the image, write its LaTeX code between $$\\n and \\n$$\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": url,\n",
    "                    \"resized_height\": 280,\n",
    "                    \"resized_width\": 280,\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": caption\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    img_inputs, _ = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=img_inputs,\n",
    "        padding=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    inputs = {key: value.tolist() for key, value in inputs.items()}\n",
    "    instruction = inputs\n",
    "    response = tokenizer(f'{caption}', add_special_tokens=False)\n",
    "    input_ids = (\n",
    "        instruction[\"input_ids\"][0] + response['input_ids'] + [tokenizer.pad_token_id]\n",
    "    )\n",
    "    attention_mask = instruction['attention_mask'][0] + response['attention_mask'] + [1]\n",
    "    labels = (\n",
    "        [-100] * len(instruction['input_ids'][0])\n",
    "        + response['input_ids']\n",
    "        + [tokenizer.pad_token_id]\n",
    "    )\n",
    "\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    \n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    inputs['pixel_values'] = torch.tensor(inputs['pixel_values'])\n",
    "    # Áî± (1, h, w) ÂèòÊç¢‰∏∫ (h, w)\n",
    "    inputs['image_grid_thw'] = torch.tensor(inputs['image_grid_thw']).squeeze(0)  \n",
    "    return {\n",
    "        \"input_ids\": input_ids, \n",
    "        \"attention_mask\": attention_mask, \n",
    "        \"labels\": labels,\n",
    "        \"pixel_values\": inputs['pixel_values'], \n",
    "        \"image_grid_thw\": inputs['image_grid_thw']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d196971e02045878af4207ac4ad85df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1019 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef40fce245bf46409c54181684e8d373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['message', 'input_ids', 'attention_mask', 'labels', 'pixel_values', 'image_grid_thw'],\n",
       "     num_rows: 1019\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['message'],\n",
       "     num_rows: 180\n",
       " }))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Êï∞ÊçÆÈõÜÂáÜÂ§á \"\"\"\n",
    "import json\n",
    "import random\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "dataset_dir = 'data/ft_data.json'\n",
    "dataset = load_dataset('json', data_files=dataset_dir)  # load dataset\n",
    "dataset = dataset['train'].train_test_split(test_size=0.15, shuffle=True, seed=5525)  # split\n",
    "dataset.save_to_disk('data/ft_dataset')  # save dataset\n",
    "\n",
    "training_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "training_dataset = training_dataset.map(preprocess_func)  # mapping training dataset\n",
    "\n",
    "training_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÈÖçÁΩÆ swanlab\n",
    "\n",
    "Â¶ÇÊûúÊÉ≥ËÆ∞ÂΩï‰∏ãËÆ≠ÁªÉÂèØËßÜÂåñÊï∞ÊçÆÔºåÂèØ‰ª•Áî® swanlabÔºåÊ≤°ÊúâÂú®‰∏ãÈù¢ Trainer ÈáåÊää `callbacks=[swanlab_callback],  # Ê≤°ÊúâÊ≥®ÈáäÂç≥ÂèØ` Ê≥®ÈáäÂç≥ÂèØÔºåÂêåÊó∂ËÆæÁΩÆ `test_results` ÂáΩÊï∞ÁöÑ `return_list=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swanlab\n",
    "from swanlab.integration.transformers import SwanLabCallback\n",
    "\n",
    "# ËÆæÁΩÆSwanLabÂõûË∞É\n",
    "swanlab_callback = SwanLabCallback(\n",
    "    project=\"Qwen2.5-VL-7b-finetune-with-test\",\n",
    "    experiment_name=\"qwen2.5-vl-crohme2019\",\n",
    "    config={\n",
    "        \"model\": \"https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct-AWQ\",\n",
    "        \"dataset\": \"https://disk.pku.edu.cn/anyshare/en-us/link/AAF10CCC4D539543F68847A9010C607139?_tb=none&expires_at=1970-01-01T08%3A00%3A00%2B08%3A00&item_type=&password_required=false&title=HMER%20Dataset&type=anonymous\",\n",
    "        \"github\": \"https://github.com/Wooonster/HOCR\",\n",
    "        \"prompt\": \"Recognize the equation in the image, write its LaTeX code bettwen $$\\t and \\t$$\",\n",
    "        \"train_data_number\": len(training_dataset),\n",
    "        \"lora_rank\": 8,\n",
    "        \"lora_alpha\": 16,\n",
    "        \"lora_dropout\": 0.1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### È¢ÑÊµã„ÄÅÊµãËØïÂáΩÊï∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_funcs import compute_bleu, compute_exprate\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(messages, model):\n",
    "    # ÂáÜÂ§áÊé®ÁêÜ\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    # ÁîüÊàêËæìÂá∫\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    return output_text[0]\n",
    "\n",
    "def test_results(dataset, model, return_list=False):\n",
    "    # test_dataset = dataset['test']\n",
    "    test_outputs = []\n",
    "    swan_list = []\n",
    "    \n",
    "    for item in dataset:\n",
    "        url = item[\"message\"][0][\"conversation\"][0]['url']\n",
    "        caption = item[\"message\"][0][\"conversation\"][1]['caption']\n",
    "        # Create the conversation prompt\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"You are a helpful assistant in recognizing math equations in either handwritten or printed text.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Recognize the equation in the image, directly write its LaTeX code between `<start_latex>` and `<end_latex>` without other words.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": url,\n",
    "                        \"resized_height\": 280,\n",
    "                        \"resized_width\": 280,\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "        # Generate a prediction using the model\n",
    "        response = predict(messages, model)\n",
    "        # Save the prediction keyed by image URL\n",
    "        test_outputs.append([url, response, caption])\n",
    "        swan_list.append(swanlab.Image(url, caption=response))\n",
    "        \n",
    "    # Compute evaluation metrics\n",
    "    compute_bleu(test_outputs)\n",
    "    compute_exprate(test_outputs)\n",
    "    \n",
    "    return swan_list if return_list else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv3d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------Computing BLEU--------------------------------------------------\n",
      "['b^xa^{y+n}===b^{x}a^{y+n}', '\\\\left[\\\\begin{array}{cc}\\n\\\\overline{a}+i\\\\frac{\\\\beta}{2}&b+i\\\\frac{\\\\beta}{2}\\n\\\\end{array}\\\\right]===[a+i\\\\frac{\\\\beta}{2},b+i\\\\frac{\\\\beta}{2}]', 'g+\\\\lambda+n=(n-1)+\\\\lambda+n=2n===g+1+n=(n-1)+1+n=2n', '\\\\sum_{r=1}^{r_{\\\\max}}\\\\frac{1}{r}===\\\\sum\\\\limits_{r=1}^{r_{max}}\\\\frac{1}{r}', '\\\\lambda=\\\\Lambda\\\\div\\\\lambda_0===l=1\\\\div10', '\\\\inte=0===\\\\intb=0', '\\\\frac{3}{xP(x)}===\\\\frac{3}{xP(x)}', 'x_1+ix_2=(x_1+ix_2)+\\\\lambda===x_{1}+ix_{2}=(x_{1}+ix_{2})+1', '\\\\sinL_t===\\\\sinLt', '\\\\Deltay=q_yx===xy=qyx', '\\\\frac{6}{\\\\sqrt{360}}===\\\\frac{6}{\\\\sqrt{360}}', '\\\\frac{b}{a_b}===b_{ab}n^{a}n^{b}', 'y^2=x^2(x+a)===y^{2}=x^{2}(x+a)', '\\\\frac{M}{\\\\sqrt{\\\\epsilon}}===M\\\\rightarrow\\\\frac{M}{\\\\sqrt{c}}', '\\\\frac{1}{64}(m+2)(3m^2+22m+40)===\\\\frac{1}{64}(n+2)(3n^{2}+22n+40)', '\\\\sin^2(t-t_0)===\\\\sin^{n}(t-t_{0})', '3\\\\timesn===3\\\\timesn', 'x^6-x^9===x^{6}-x^{9}', '\\\\left((a+b+\\\\ldots+c)\\\\right)^2\\\\geqa^2+b^2+\\\\ldots+c^2===(a+b+\\\\ldots+c)^{2}\\\\geqa^{2}+b^{2}+\\\\ldots+c^{2}', 'f^{2}-f+x=0===f^{2}-f+x=0', '\\\\sum_{m}^{2}===\\\\summ^{2}', 'y=x_{21}^{-1}x_{13}^{-1}x_{34}^{-1}x_{42}===z=x_{21}x_{13}^{-1}x_{34}x_{42}^{-1}', '\\\\alpha=x+iy===a=x+iy', 'x(r)=x_0+x_1r+x_2r^2+\\\\ldots===x(t)=x_{0}+x_{1}t+x_{2}t^{2}+\\\\ldots', '44=\\\\frac{9(9+1)}{2}-1===44=\\\\frac{9(9+1)}{2}-1', 'A_6S(3)\\\\timesS(3)\\\\timesS(3)\\\\timesS(4)===AdS(3)\\\\timesS(3)\\\\timesS(3)\\\\timesS(1)', '\\\\left(0\\\\mid1000000\\\\right)===(001000000)', '\\\\left(c=\\\\sum_{n=1}^{m}n^2\\\\right)===C=\\\\sum\\\\limits_{n=1}c_{n}n^{2}', 'y^*=4x^3+Ax+B===y^{2}=4x^{3}+Ax+B', 'C=-m\\\\cosa===C=-m\\\\cosa', 'x^4+ux^2+qx+r=0===x^{4}+ux^{2}+qx+r=0', '-8-\\\\frac{1}{8}===-8-\\\\frac{1}{8}', '\\\\forallm,m\\\\geqslant1===\\\\forallm,n\\\\geq1', '\\\\left(1+1+a+a\\\\right)+(4\\\\times0)+(4\\\\times0)===(1+1+0+0)+(4\\\\times0)+(4\\\\times0)', '\\\\sum(-1)^mx_{2n}===\\\\sum(-1)^{n}x_{2n}', '\\\\frac{899}{528}===\\\\frac{899}{528}', '\\\\gamma=\\\\tan^2t===r=\\\\tan^{2}t', '\\\\sqrt{-t}===\\\\sqrt{-t}', '\\\\left(1\\\\right)+\\\\left(11\\\\right)+\\\\left(111\\\\right)+\\\\left(112\\\\right)+\\\\left(123\\\\right)===(1)+(11)+(111)+(112)+(123)', '\\\\int_0^3x\\\\,dx===\\\\intd^{3}x', '\\\\frac{\\\\lambda}{\\\\sqrt{8}}===\\\\frac{1}{\\\\sqrt{8}}', 'm=M_0+M_1+M_2\\\\Delta(C-1)-2M_3\\\\Delta(S+1)===M=M_{0}+M_{1}Y+M_{2}[I(I+1)-\\\\frac{1}{4}Y^{2}]-M_{3}S(S+1)', '0+8512m^2+3.923m-6.620===0.7851n^{2}+3.929n-6.620', '\\\\frac{p(-x)}{x\\\\frac{(xp(x))^2}{1}}===x\\\\frac{P(-x)}{(xP(x))^{2}}', '\\\\sum_{a=1}^{4}c_a=2B+4F===\\\\sum\\\\limits_{a=1}^{4}C_{a}=2B+4F', '2^{p-5}-\\\\left(\\\\frac{1}{2}-2^{p-5}\\\\right)=2^{p-4}-\\\\frac{1}{2}===2^{p-5}-(\\\\frac{1}{2}-2^{p-5})=2^{p-4}-\\\\frac{1}{2}', '\\\\begin{equation}\\nE_0=-\\\\lambda+\\\\frac{\\\\lambda}{4}+\\\\frac{\\\\lambda}{2}-\\\\frac{\\\\lambda}{8}=-\\\\frac{3}{4}\\n\\\\end{equation}===E_{0}=-1+4\\\\frac{1}{4}\\\\frac{1}{2}\\\\frac{1}{2}=-\\\\frac{3}{4}', '\\\\sqrt{s},\\\\sqrt{s-b},\\\\sqrt{s-a}===\\\\sqrt{s},\\\\sqrt{s-b},\\\\sqrt{s-a}', '-\\\\frac{3+z^2}{8}-\\\\frac{(3+z^2)^2}{32}===-\\\\frac{3+z^{2}}{8}-\\\\frac{(3+z^{2})^{2}}{32}', 'j^2=-\\\\left(\\\\frac{m}{2}+1\\\\right)-\\\\left(\\\\frac{m}{2}+\\\\frac{1}{2}\\\\right)k^{-2}===j_{2}=-(\\\\frac{n}{2}+1)-(\\\\frac{m}{2}+\\\\frac{1}{2})b^{-2}', 'y_1(x)\\\\partial_x===y_{1}(x)\\\\logx', 'k+x===k+x', '\\\\sum_{i}P_i=\\\\sum_{i}P_i^2=1===\\\\sum\\\\limits_{i}p_{i}=\\\\sum\\\\limits_{i}p_{i}^{2}=1', '\\\\sin\\\\theta=\\\\frac{119}{120}===\\\\sin\\\\theta=\\\\frac{119}{120}', '2.71\\\\ldots===2.71\\\\ldots', '\\\\begin{equation}\\n\\\\betay^2=4\\\\alpha^3-8_2\\\\beta^2\\\\alpha-8_3\\\\beta^3\\n\\\\end{equation}===zy^{2}=4x^{3}-g_{2}z^{2}x-g_{3}z^{3}', 'C<C_{cr}===c<c_{cr}', '\\\\lambda=\\\\lambda_0=2+\\\\sqrt{3}===x=x_{0}=2+\\\\sqrt{3}', 'C\\\\geq0===C\\\\geq0', 'E=\\\\sqrt{2}\\\\int_{-1}^{+1}df\\\\sqrt{V(f)}===E=\\\\sqrt{2}\\\\int\\\\limits_{-1}^{+1}df\\\\sqrt{V(f)}', '\\\\frac{6}{\\\\sqrt{60}}===\\\\frac{6}{\\\\sqrt{60}}', '\\\\cos\\\\theta===\\\\coskx', 'z=x^{2+2}+ix^{4+3}===z=x^{2i+2}+ix^{2i+3}', \"x'y'=qy'x'===x^{1}y^{1}=qy^{1}x^{1}\", '2^{22}===2^{22}', 'a=n+\\\\frac{1}{2}(n+\\\\frac{5}{6})===a=n+\\\\frac{1}{2},n+\\\\frac{5}{6}', 'A=\\\\sum_{a}A^{a}t^{a}===A=\\\\sum\\\\limits_{a}A^{a}t^{a}', 'z=\\\\frac{-b}{a}===z=\\\\frac{-b}{a}', 'x_0+g(x-x_0)===x_{0}+g(x-x_{0})', '\\\\frac{777}{400}===\\\\frac{777}{400}', '\\\\frac{11-3+5\\\\sqrt{3}+3^3}{16}===-\\\\frac{11-z+5z^{2}+z^{3}}{16}', '\\\\sin\\\\theta_1\\\\sin\\\\theta_2\\\\sin\\\\theta_3\\\\sin\\\\theta_4===\\\\sin\\\\theta_{1}\\\\sin\\\\theta_{2}\\\\sin\\\\theta_{3}\\\\sin\\\\theta_{4}', '\\\\lim_{d\\\\to\\\\infty}(R_{ab}-\\\\frac{1}{2}R_{a0b})/(Cd-2)===\\\\lim\\\\limits_{d\\\\rightarrow2}(R_{ab}-\\\\frac{1}{2}Rg_{ab})/(d-2)', '-\\\\frac{1}{3}\\\\intA^3===-\\\\frac{1}{3}\\\\intA^{3}', 'x_1^2+x_2^2+x_3^2=1===x_{1}^{2}+x_{2}^{2}+x_{3}^{2}=1', 'b^2=7+\\\\frac{u^2}{2}=\\\\frac{1}{E^2}===b^{2}=1+\\\\frac{u^{2}}{2}=\\\\frac{1}{E^{2}}', '\\\\sin\\\\theta_1\\\\sin\\\\theta_2\\\\sin\\\\theta_3===\\\\sin\\\\theta_{1}\\\\sin\\\\theta_{2}\\\\sin\\\\theta_{3}', '\\\\frac{n(2n-1)(2n+1)}{3}===\\\\frac{n(2n-1)(2n+1)}{3}', '2\\\\intR_{ab}R^{b}c===2\\\\intR_{ab}R^{ab}c', '\\\\int_{0}^{1}x\\\\,dx===\\\\intd^{4}x\\\\sqrt{g}', '\\\\pi=\\\\sqrt{a^a}===r=\\\\sqrt{y^{a}y^{a}}', '\\\\int(p+1)===\\\\intC^{(p+1)}', '\\\\sum_{a}\\\\in\\\\mathbb{K},\\\\sum_{m}\\\\in\\\\mathbb{M}===\\\\sumn_{\\\\alpha}\\\\leqn,\\\\summ_{\\\\alpha}\\\\leqm', '\\\\frac{n-2}{n}\\\\left[\\\\frac{B(1-n)}{C(3n-4)}\\\\right]^{\\\\frac{n-2}{2n}}===2^{\\\\frac{n-2}{n}}[\\\\frac{B(1-n)}{C(3n-4)}]^{\\\\frac{n-2}{2n}}', '\\\\sqrt{\\\\delta_{yy}}===\\\\sqrt{g_{yy}}', '\\\\sin^2x=\\\\frac{1}{2}(1-\\\\cos(2x))===\\\\sin^{2}x=\\\\frac{1}{2}(1-\\\\cos(2x))', '\\\\left(C\\\\timesC\\\\right)===C\\\\timesC', '\\\\int\\\\frac{1}{x}dx===\\\\intdX', 'j\\\\geq3===j\\\\geq3', '\\\\log(-x)=\\\\log(x)+i\\\\pi===\\\\log(-x)=\\\\log(x)+i\\\\pi', 'r=\\\\sqrt{(x^4)^2+(x^8)^2}===r=\\\\sqrt{(x^{1})^{2}+(x^{2})^{2}}', 'T=\\\\lim_{v\\\\to\\\\infty}v^3===T=\\\\lim\\\\limits_{u\\\\rightarrow\\\\infty}uz', '\\\\gamma_{\\\\alpha}===qyx', 'x^{14}+x^{12}+x^{24}=C===X^{11}+X^{12}+X^{21}=C', 'S^2\\\\timesS^3\\\\timesS^4\\\\timesS^2===S^{2}\\\\timesS^{2}\\\\timesS^{2}\\\\timesS^{2}', '\\\\frac{-4}{\\\\sqrt{60}}===\\\\frac{-4}{\\\\sqrt{60}}', '\\\\intdA===\\\\intdA', '\\\\frac{2\\\\pi}{\\\\beta}\\\\left(n+\\\\frac{1}{2}\\\\right)===\\\\frac{2\\\\pi}{\\\\beta}(n+\\\\frac{1}{2})', '\\\\int_{x}^{y}c_i===\\\\int\\\\limits_{x}^{y}c_{i}', 'f(x)=(x_a^2-x_b^2)===f(x)=(x_{a}^{2}-x_{b}^{2})', '\\\\lim_{y\\\\to\\\\infty}u(y)=5===\\\\lim\\\\limits_{y\\\\rightarrow\\\\infty}u(y)=s', 'y=\\\\sqrt{y_1y_2}===y=\\\\sqrt{y_{i}y^{i}}', 'F(x)=x\\\\left(1+\\\\frac{x}{a}\\\\right)===F(x)=x(1+\\\\frac{x}{a})', '\\\\left(\\\\frac{1}{3}+\\\\frac{5}{2x^2n^2}\\\\right)===(\\\\frac{1}{3}+\\\\frac{5}{2\\\\pi^{2}n^{2}})', '\\\\lim_{t\\\\to\\\\infty}|r(t)|=\\\\infty===\\\\lim\\\\limits_{t\\\\rightarrow\\\\infty}|\\\\gamma(t)|=\\\\infty', '\\\\frac{i}{r+i}=1-\\\\frac{k}{rti}===\\\\frac{i}{k+i}=1-\\\\frac{k}{k+i}', 'h_{xx}=-h_{yy}===h_{xx}=-h_{yy}', '\\\\log\\\\left(x^{2}+y^{2}\\\\right)===\\\\log(x^{2}+y^{2})', '\\\\frac{m}{\\\\sqrt{2}}===\\\\frac{m}{\\\\sqrt{2}}', '1.0737+1.2227===1.0737+1.2227', 'g(x)=\\\\beta_{ab}2^{a}x^{b}===g(x)=\\\\beta_{ab}x^{a}x^{b}', 'z=\\\\intdy\\\\bar{a}^{-1}(y)===z=\\\\intdya^{-1}(y)', '-9.9599===-9.9599', '\\\\tan\\\\theta/2===\\\\tan\\\\theta/2', 'n!\\\\binom{m}{n}(z)=(-z)^{n-m}m!\\\\binom{n-m}{m}(z)===n!L_{n}^{(m-n)}(z)=(-z)^{n-m}m!L_{m}^{(n-m)}(z)', 't>x===t>x', '\\\\cos^2\\\\theta_0===\\\\cosz_{0}', 'F=\\\\frac{1}{4}F_{ab}F^{ab}===F=\\\\frac{1}{4}F_{ab}F^{ab}', 'x^3x^4x^5===x^{3}x^{4}x^{5}', 'x^m-ax^4+b=0===x^{n}-ax^{s}+b=0', 'X=0.1,0.2\\\\ldots===X=0.1,0.2\\\\ldots', 'x_{0}dy=q_{1}dx+(q_{1}^{2}-1)dx===xdy=qdyx+(q^{2}-1)dxy', 'a=\\\\sqrt{\\\\frac{\\\\beta}{\\\\alpha}}===a=\\\\sqrt{\\\\frac{\\\\beta}{\\\\alpha}}', '\\\\frac{149}{84}===\\\\frac{149}{84}', '\\\\left(\\\\lambda_1-\\\\frac{\\\\lambda}{3},-\\\\frac{\\\\lambda}{3}\\\\right)-\\\\frac{\\\\lambda}{3}===(1,-\\\\frac{1}{3},-\\\\frac{1}{3},-\\\\frac{1}{3})', '\\\\frac{n}{2}+\\\\frac{7}{2}===\\\\frac{n}{2}+\\\\frac{7}{2}', '\\\\frac{3+z^2}{8}+\\\\frac{(3+z^2)^2}{32}===\\\\frac{3+z^{2}}{8}+\\\\frac{(3+z^{2})^{2}}{32}', '\\\\frac{9}{2}===\\\\frac{9}{2}', '\\\\sum_{q_i}=-\\\\frac{1}{q}===\\\\sumq_{i}=-\\\\frac{1}{4}', '\\\\left(\\\\frac{\\\\rho^{2}-\\\\rho}{1+\\\\rho}-1\\\\right)===(\\\\frac{p2^{-p}}{1+p}-1)', 'x^2+y^5+z^3===x^{2}+y^{5}+z^{3}', 'a=3\\\\left(4-\\\\sqrt{10}\\\\right)\\\\sqrt{5}/\\\\left(14\\\\sqrt{10}-5\\\\right)===a=3(4-\\\\sqrt{10})\\\\sqrt{10}/(14\\\\sqrt{10}-5)', '\\\\left(\\\\lambda_{2S}\\\\right)-\\\\left(\\\\lambda_{SS}\\\\right)+\\\\left(\\\\gamma_{3S}\\\\right)-\\\\left(\\\\gamma_{2S}\\\\right)\\\\left(\\\\beta_{2G}\\\\right)-\\\\left(\\\\gamma_{3S}\\\\right)===(125)-(135)+(735)-(725)-(1246)-(73)', 'a\\\\neq-b===a\\\\neq-b', '2f-e_1-e_3+2e_5+e_7+2e_9===2f-e_{1}-e_{3}+2e_{6}+e_{7}+2e_{9}', '8\\\\cos\\\\theta===8\\\\cos\\\\theta', '\\\\summ_B^2-\\\\summ_F^2=0===\\\\summ_{B}^{2}-\\\\summ_{F}^{2}=0', '25^{\\\\frac{8}{3}}\\\\sqrt[5]{2^{-24}}===25\\\\sqrt[5]{2^{-21}3^{8}}', '\\\\cos\\\\left[\\\\frac{m}{2}\\\\sigma\\\\right]===\\\\tan[\\\\frac{n}{2}\\\\sigma]', '\\\\limy===\\\\limy', '\\\\alpha=\\\\frac{1}{\\\\tan\\\\theta}===\\\\alpha=\\\\frac{1}{\\\\tan\\\\theta}', '\\\\int_{\\\\mathbb{R}^n}===\\\\intR^{n}', '\\\\frac{325}{66}===\\\\frac{325}{66}', '\\\\frac{-4}{\\\\sqrt{360}}===\\\\frac{-4}{\\\\sqrt{360}}', '-\\\\frac{1}{2}<a+\\\\frac{1}{2}<0===-\\\\frac{1}{2}<a+\\\\frac{1}{2}<0', '\\\\left(ab\\\\right)=\\\\frac{1}{2}\\\\left(ab+ba\\\\right)===(ab)=\\\\frac{1}{2}(ab+ba)', '\\\\rho_{\\\\text{max}}=\\\\frac{8\\\\sqrt{3}}{15}=0.924===P_{max}=\\\\frac{8\\\\sqrt{3}}{15}=0,924', '\\\\sigma(\\\\omega)=\\\\sum_{n}C_n\\\\omega^{n+1}===c(w)=\\\\sum\\\\limits_{n}c_{n}w^{-n+1}', 'C=\\\\frac{1}{32}+\\\\frac{1}{96}\\\\log2===C=\\\\frac{1}{32}+\\\\frac{1}{96}\\\\log2', '-\\\\alpha_{p-1}+2\\\\alpha_p-\\\\alpha_{p+1}+X=0===-a_{p-1}+2a_{p}-a_{p+1}+X=0', '\\\\int^{ab}=d^{ab}+a^{ac}q^{cb}===f^{ab}=da^{ab}+a^{ac}a^{cb}', '-\\\\intb===-\\\\intbB', 'x^{n-1}+xy^2+z^2===x^{n-1}+xy^{2}+z^{2}', 'f(y)=y^{\\\\frac{1}{n-2}}===f(y)=y^{\\\\frac{1}{n-2}}', 'b_c=\\\\frac{1}{2}\\\\log(\\\\sqrt{2}+1)===b_{c}=\\\\frac{1}{2}\\\\log(\\\\sqrt{2}+1)', '\\\\frac{1}{C}===\\\\frac{1}{c}', '\\\\sum_{m-p-2,\\\\,p}(m-p-1)===t_{n-p-2a_{p}}^{(n-p-1)}', 'xy=yx===xy=yx', 'T(x)=iu\\\\sin(x)===T(x)=iu\\\\sin(x)', '\\\\tau=\\\\frac{x^0-x^9}{2}===v=\\\\frac{x^{0}-x^{9}}{2}', '\\\\left(\\\\begin{array}{cc}\\n\\\\frac{\\\\Lambda}{2}&\\\\frac{\\\\Lambda}{2}\\\\\\\\\\n\\\\frac{\\\\Lambda}{2}&\\\\frac{\\\\Lambda}{2}\\n\\\\end{array}\\\\right)===(\\\\frac{1}{2}\\\\frac{1}{2}\\\\frac{1}{2}\\\\frac{1}{2}0000)', '\\\\sqrt{kx}===k\\\\timesx', 'x=\\\\frac{9}{5}-2===x\\\\div5\\\\div2', '\\\\int_{-m}^{n}d^4x===\\\\int\\\\limits_{-n}^{n}d^{4}x', '\\\\lim_{x\\\\to\\\\pm\\\\infty}P\\\\left(\\\\frac{e^{ikx}}{k}\\\\right)===\\\\lim\\\\limits_{x\\\\rightarrow\\\\pm\\\\infty}P(\\\\frac{e^{ikx}}{k})', '\\\\Lambda=\\\\frac{4Bx^2\\\\sqrt{1-x}}{\\\\sqrt{1+3x}}-4(8+\\\\log(4))===b-\\\\frac{4B\\\\pi^{2}\\\\sqrt{1-x}}{\\\\sqrt{1+3x}}-4(\\\\gamma+\\\\log(4))', 'f_{n-1}(x)=b_{n-n}x^{n-1}+\\\\ldots+b_0===f_{n-1}(x)=b_{n-1}x^{n-1}+\\\\ldots+b_{0}', '\\\\sqrt{\\\\cos(x)}===\\\\sqrt[c]{\\\\cos(x)}', '\\\\sqrt{A+t}===\\\\sqrt{1+t}', '\\\\sin(n\\\\pi)===\\\\sin(nv)', '\\\\Lambda=\\\\frac{\\\\Lambda_2}{\\\\Lambda_1-1}=\\\\frac{\\\\Lambda_3}{\\\\Lambda_1-1}===n=\\\\frac{n_{2}}{n_{1}-1}=\\\\frac{n_{3}}{n_{1}-1}', '\\\\sqrt{\\\\frac{R}{n}}===\\\\sqrt{\\\\frac{k}{n}}', '\\\\int_0^dxe(x)===\\\\intd^{d}xe(x)', 'q_c(t)=\\\\operatorname{Sim}(Ht)===a(t)=\\\\sin(Ht)', '\\\\beta=\\\\sqrt{\\\\alpha}===\\\\beta=\\\\sqrt{2ab}', 'H=\\\\sqrt{\\\\frac{5}{2}}\\\\left(\\\\frac{1}{\\\\alpha-1}+\\\\frac{1}{2}\\\\right)===H=\\\\sqrt{\\\\frac{5}{2}}(\\\\frac{1}{(x-1)}+\\\\frac{1}{2})', '\\\\cos(u)===\\\\cos(v)', '\\\\sin(\\\\theta)\\\\neq0===\\\\sin(\\\\theta)\\\\neq0', '\\\\sin(\\\\theta)===\\\\sin(\\\\theta)', '\\\\left(1-x\\\\right)^{c-a-b}===(1-x)^{c-a-b}']\n",
      "Average BLEU score: 0.6020\n",
      "--------------------------------------------------Computing ExpRate--------------------------------------------------\n",
      "ExpRate: 26.67%\n",
      "ExpRate (<=1 error): 30.00%\n",
      "ExpRate (<=2 errors): 32.22%\n"
     ]
    }
   ],
   "source": [
    "test_results(test_dataset, model_7b, return_list=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÈÖçÁΩÆ LoRA ÂèÇÊï∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model, PeftModel\n",
    "\n",
    "# ÈÖçÁΩÆLoRA\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=False,  # ËÆ≠ÁªÉÊ®°Âºè\n",
    "    r=8,  # Lora Áß©\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,  # Dropout ÊØî‰æã\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# Ëé∑ÂèñLoRAÊ®°Âûã\n",
    "peft_model_7b = get_peft_model(model_7b, config)\n",
    "peft_model_7b.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÈÖçÁΩÆÈ¢ÑËÆ≠ÁªÉÂèÇÊï∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Qwen2VLForConditionalGeneration,\n",
    "    AutoProcessor,\n",
    ")\n",
    "\n",
    "# ÈÖçÁΩÆËÆ≠ÁªÉÂèÇÊï∞\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./model/output/Qwen2.5-VL-7B-ft/\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=4,  # total batch size = per_device_train_batch_size * gradient_accumulation_steps\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=25,\n",
    "    logging_first_step=True,\n",
    "    num_train_epochs=3,\n",
    "    # eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type='cosine',\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"none\",\n",
    "    # load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÂºÄÂßãËÆ≠ÁªÉÔºåÂπ∂‰∏îÁ®≥ÂÆöÂêéÔºåÂú®ÁªàÁ´Ø `watch -n 1 nvidia-smi` ËßÇÊµã‰∏Ä‰∏ã GPU ÊòæÂ≠òÂç†Áî®ÊÉÖÂÜµÔºåÂèØ‰ª•ËÆ∞ÂΩï‰∏Ä‰∏ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Tracking run with swanlab version 0.4.8                                   \n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Run data will be saved locally in \u001b[35m\u001b[1m/root/autodl-tmp/HOCR/finetune/swanlog/run-20250320_234301-a3b1799d\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: üëã Hi \u001b[1m\u001b[39mWonster\u001b[0m\u001b[0m, welcome to swanlab!\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Syncing run \u001b[33mqwen2.5-vl-crohme2019\u001b[0m to the cloud\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: üåü Run `\u001b[1mswanlab watch /root/autodl-tmp/HOCR/finetune/swanlog\u001b[0m` to view SwanLab Experiment Dashboard locally\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: üè† View project at \u001b[34m\u001b[4mhttps://swanlab.cn/@Wonster/Qwen2.5-VL-7b-finetune-with-test\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://swanlab.cn/@Wonster/Qwen2.5-VL-7b-finetune-with-test/runs/oxj92mh6897rqo10054nr\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Show Iframe</title>\n",
       "    \n",
       "        <script>\n",
       "            function showIframe() {\n",
       "                var iframeHtml = '<iframe src=\"https://swanlab.cn/@Wonster/Qwen2.5-VL-7b-finetune-with-test/runs/oxj92mh6897rqo10054nr\" width=100% height=\"600\" frameborder=\"no\"></iframe>';\n",
       "                document.getElementById('iframeContainer').innerHTML = iframeHtml;\n",
       "            }\n",
       "        </script>\n",
       "        \n",
       "</head>\n",
       "<body>\n",
       "    <style>\n",
       "        .interactive-button {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            height: 36px;\n",
       "            border: 0px;\n",
       "            background-color: #2c8f63;\n",
       "            color: white;\n",
       "            padding: 10px 20px;\n",
       "            transition: background-color 0.3s, transform 0.2s;\n",
       "        }\n",
       "\n",
       "        .interactive-button:hover {\n",
       "            background-color: #5cab87;\n",
       "            cursor: pointer;\n",
       "        }\n",
       "\n",
       "        .interactive-button:active { background-color: #217952; transform: scale(0.96); } </style> <br> <button \n",
       "        onclick=\"showIframe()\" class=\"interactive-button\"> <svg style=\"height: 16px; margin-right: 8px;\" viewBox=\"0 0 \n",
       "        46 46\" fill=\"none\"> <path d=\"M10.8439 21.1974C10.6414 21.2854 10.4477 21.3925 10.2655 21.5173L10.2069 \n",
       "        21.5652C10.1839 21.58 10.1625 21.5969 10.1429 21.6159C6.29135 24.6118 4.22831 29.4416 5.32646 34.282C5.94656 \n",
       "        37.0577 7.50461 39.5348 9.73801 41.2958C11.9714 43.0568 14.7436 43.994 17.5874 43.9495H18.0219C19.8864 \n",
       "        43.8697 21.7087 43.3694 23.3526 42.486C24.9964 41.6026 26.4193 40.3589 27.5147 38.848C28.61 37.3371 29.3496 \n",
       "        35.598 29.678 33.761C30.0065 31.9239 29.9153 30.0363 29.4112 28.2395C28.9181 26.4723 27.8919 24.8437 26.9937 \n",
       "        23.2551C25.4158 20.4653 23.8343 17.6764 22.2492 14.8884C21.7801 14.0647 21.3057 13.2465 20.8419 \n",
       "        12.4228C20.2315 11.3353 19.2746 10.1519 19.224 8.86183C19.1733 7.57176 20.2235 6.32701 21.5082 \n",
       "        6.07912C23.9284 5.61801 25.0639 8.24078 25.0693 8.23812C25.363 8.94035 25.9123 9.50489 26.6063 \n",
       "        9.81764C27.3002 10.1304 28.087 10.168 28.8077 9.92298C29.5283 9.67791 30.1291 9.1684 30.4885 8.49743C30.8479 \n",
       "        7.82646 30.9392 7.04405 30.7439 6.30835C30.1514 4.37314 28.9133 2.69953 27.2363 1.56656C25.7615 0.511704 \n",
       "        23.9847 -0.0372109 22.1719 0.00195984C20.9049 0.00893199 19.6532 0.27989 18.4967 0.797557C17.3402 1.31522 \n",
       "        16.3043 2.06823 15.4551 3.00856C14.49 4.08707 13.7984 5.38193 13.4389 6.78385C13.0794 8.18576 13.0624 9.6536 \n",
       "        13.3894 11.0635C13.52 11.593 13.6984 12.1095 13.9225 12.6067C14.5595 14.0514 15.4951 15.3681 16.284 \n",
       "        16.7355C17.2525 18.4147 18.2209 20.0948 19.1893 21.7758C20.1578 23.4568 21.1351 25.1449 22.1213 \n",
       "        26.8401C22.9209 28.2421 23.7925 29.4682 23.8805 31.1528C23.9175 32.0513 23.7682 32.9479 23.4419 \n",
       "        33.7859C23.1156 34.6239 22.6194 35.3854 21.9845 36.0223C21.3496 36.6592 20.5897 37.1578 19.7527 \n",
       "        37.4868C18.9157 37.8157 18.0196 37.9678 17.121 37.9336C14.0024 37.7923 11.6488 35.4814 11.1744 32.4588C10.58 \n",
       "        28.6419 13.552 26.5469 13.552 26.5469C14.1782 26.1785 14.6497 25.5955 14.8791 24.906C15.1084 24.2166 15.0801 \n",
       "        23.4673 14.7993 22.7971C14.5186 22.127 14.0044 21.5813 13.3521 21.2611C12.6998 20.941 11.9536 20.8682 11.2517 \n",
       "        21.0561C11.1174 21.0939 10.9856 21.1402 10.8572 21.1947\" fill=\"white\" /> <path d=\"M42.8101 31.5968C42.8109 \n",
       "        30.5198 42.7218 29.4445 42.5435 28.3823C42.2663 26.7069 41.7464 25.0808 41.0002 23.5552C40.5524 22.6463 \n",
       "        39.9874 21.7374 39.1024 21.2417C38.6593 20.9919 38.1589 20.8617 37.6502 20.8639C37.1416 20.8661 36.6423 \n",
       "        21.0006 36.2013 21.2541C35.7604 21.5077 35.393 21.8716 35.1352 22.3101C34.8775 22.7485 34.7382 23.2466 \n",
       "        34.7312 23.7552C34.7072 24.8773 35.3149 25.8875 35.768 26.9217C36.5212 28.6453 36.8623 30.5208 36.7642 \n",
       "        32.3993C36.6661 34.2777 36.1315 36.1075 35.2029 37.7433C35.146 37.8404 35.0952 37.941 35.051 38.0445C34.8623 \n",
       "        38.4842 34.7635 38.9573 34.7605 39.4358C34.7802 40.1222 35.0356 40.7808 35.4835 41.3011C35.9315 41.8214 \n",
       "        36.5449 42.1717 37.2207 42.2932C38.8759 42.589 40.1899 41.347 40.8856 39.9609C42.1643 37.3589 42.823 34.4961 \n",
       "        42.8101 31.5968Z\" fill=\"white\" /> <path d=\"M28.2309 11.8938C28.1761 11.9043 28.1218 11.9176 28.0683 \n",
       "        11.9338C27.9593 11.9642 27.8611 12.0249 27.7851 12.1088C27.7091 12.1928 27.6584 12.2965 27.6389 \n",
       "        12.408C27.6193 12.5195 27.6318 12.6343 27.6748 12.7391C27.7178 12.8438 27.7895 12.9343 27.8818 \n",
       "        12.9999C29.2375 14.0252 30.3809 15.3043 31.2482 16.7662C31.4838 17.1677 31.6888 17.5865 31.8612 \n",
       "        18.0189C32.0052 18.3921 32.1971 18.8799 32.6822 18.8532C33.0607 18.8346 33.2153 18.512 33.3192 \n",
       "        18.1895C33.8137 16.5125 33.9678 14.7534 33.7723 13.0159C33.6331 12.0693 33.4155 11.1359 33.122 \n",
       "        10.2252C33.0775 10.0047 32.9744 9.80029 32.8235 9.6335C32.7273 9.54627 32.6054 9.49262 32.4761 9.4806C32.3468 \n",
       "        9.46859 32.2171 9.49886 32.1065 9.56687C32.0016 9.65188 31.9115 9.75365 31.8399 9.86806C31.3956 10.4658 \n",
       "        30.825 10.9581 30.1687 11.3101C29.8377 11.4861 29.4893 11.6272 29.1292 11.7312C28.828 11.8192 28.5215 11.8325 \n",
       "        28.2309 11.8938Z\" fill=\"white\" /> </svg> Display SwanLab Board </button> <br> <div \n",
       "        id=\"iframeContainer\"></div> </body> </html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv3d(\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 25:52, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.379500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=189, training_loss=0.02066893583005319, metrics={'train_runtime': 1564.9777, 'train_samples_per_second': 1.953, 'train_steps_per_second': 0.121, 'total_flos': 5364319648972800.0, 'train_loss': 0.02066893583005319, 'epoch': 2.9568627450980394})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ÈÖçÁΩÆTrainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model_7b,\n",
    "    args=training_args,\n",
    "    train_dataset=training_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    "    callbacks=[swanlab_callback],  # Ê≤°ÊúâÊ≥®ÈáäÂç≥ÂèØ\n",
    ")\n",
    "\n",
    "# ÂºÄÂêØÊ®°ÂûãËÆ≠ÁªÉ\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model, PeftModel\n",
    "\n",
    "# ÈÖçÁΩÆÊµãËØïÂèÇÊï∞\n",
    "val_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=True,  # ËÆ≠ÁªÉÊ®°Âºè\n",
    "    r=8,  # Lora Áß©\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,  # Dropout ÊØî‰æã\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# Ëé∑ÂèñÊµãËØïÊ®°Âûã\n",
    "val_peft_model = PeftModel.from_pretrained(\n",
    "    model_7b, \n",
    "    model_id=\"./model/output/Qwen2.5-VL-7B-ft/checkpoint-189/\",  # Êç¢Âà∞Ëá™Â∑±ÂæÆË∞ÉÂ•ΩÁöÑÊ®°Âûã ckpt Ë∑ØÂæÑ\n",
    "    config=val_config,\n",
    "    # local_files_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------Computing BLEU--------------------------------------------------\n",
      "['$$b^{x}a^{y+n}$$===b^{x}a^{y+n}', '$$\\\\left[\\\\begin{array}{l}{-a+i\\\\frac{\\\\beta}{2}}\\\\\\\\{b+i\\\\frac{\\\\beta}{2}}\\\\end{array}\\\\right]$$===[a+i\\\\frac{\\\\beta}{2},b+i\\\\frac{\\\\beta}{2}]', '$$g+\\\\lambda+n=(n-1)+\\\\lambda+n=2n$$===g+1+n=(n-1)+1+n=2n', '\\\\sum_{r=1}^{r_{\\\\max}}\\\\frac{1}{r}===\\\\sum\\\\limits_{r=1}^{r_{max}}\\\\frac{1}{r}', '\\\\lambda=\\\\Lambda\\\\div\\\\lambda_0===l=1\\\\div10', '$$\\\\inte=0$$===\\\\intb=0', '$$\\\\frac{3}{xP(x)}$$===\\\\frac{3}{xP(x)}', 'x_{1}+ix_{2}=\\\\left(x_{1}+ix_{2}\\\\right)+i===x_{1}+ix_{2}=(x_{1}+ix_{2})+1', '$$\\\\sinLt$$===\\\\sinLt', '\\\\Deltay=q_y\\\\Deltax===xy=qyx', '$$\\\\frac{6}{\\\\sqrt{360}}$$===\\\\frac{6}{\\\\sqrt{360}}', '$$b_{ab}^{mn}$$===b_{ab}n^{a}n^{b}', '$$y^{2}=x^{2}(x+a)$$===y^{2}=x^{2}(x+a)', '$$\\\\vec{M}\\\\rightarrow\\\\frac{M}{V}$$===M\\\\rightarrow\\\\frac{M}{\\\\sqrt{c}}', '$$\\\\frac{1}{64}(m+2)(3m^{2}+22m+40)$$===\\\\frac{1}{64}(n+2)(3n^{2}+22n+40)', '\\\\sin^2(t-t_0)===\\\\sin^{n}(t-t_{0})', '<start_latex>\\n$$3\\\\timesn$$===3\\\\timesn', '$$x^{6}-x^{9}$$===x^{6}-x^{9}', '$$\\\\left((a+b+\\\\ldots+c)\\\\right)^{2}\\\\geqa^{2}+b^{2}+\\\\ldots+c^{2}$$===(a+b+\\\\ldots+c)^{2}\\\\geqa^{2}+b^{2}+\\\\ldots+c^{2}', '$$f^{2}-f+x=0$$===f^{2}-f+x=0', '$$\\\\summ^{2}$$===\\\\summ^{2}', '$$y=x_{21}\\\\;x_{13}^{-1}\\\\;x_{34}^{-1}\\\\;x_{42}$$===z=x_{21}x_{13}^{-1}x_{34}x_{42}^{-1}', '\\\\alpha=x+iy===a=x+iy', 'x(t)=x_0+x_1t+x_2t^2+\\\\ldots===x(t)=x_{0}+x_{1}t+x_{2}t^{2}+\\\\ldots', '$$44=\\\\frac{9(9+1)}{2}-1$$===44=\\\\frac{9(9+1)}{2}-1', '$$A_{0}S(3)\\\\timesS(3)\\\\timesS(3)\\\\timesS(3)$$===AdS(3)\\\\timesS(3)\\\\timesS(3)\\\\timesS(1)', '<start_latex>\\n\\\\left(60\\\\middle|1000000\\\\right)===(001000000)', '\\\\sum_{n=1}^{\\\\infty}c_nn^2===C=\\\\sum\\\\limits_{n=1}c_{n}n^{2}', '$$y^{\\\\prime}=4x^{3}+Ax+B$$===y^{2}=4x^{3}+Ax+B', '$$C=-m\\\\cosa$$===C=-m\\\\cosa', '$$\\\\begin{array}{rl}{x^{4}+ux^{2}+qx+r=}&{{}0}\\\\end{array}$$===x^{4}+ux^{2}+qx+r=0', '$$-8-\\\\frac{1}{8}$$===-8-\\\\frac{1}{8}', '$$\\\\forallm\\\\;,\\\\;m\\\\geqslant1$$===\\\\forallm,n\\\\geq1', '$$\\\\left(1+1+0+0\\\\right)+\\\\left(4\\\\times0\\\\right)+\\\\left(4\\\\times0\\\\right)$$===(1+1+0+0)+(4\\\\times0)+(4\\\\times0)', '\\\\sum(-1)^mx_{2n}===\\\\sum(-1)^{n}x_{2n}', '$$\\\\frac{899}{528}$$===\\\\frac{899}{528}', '$$\\\\gamma=\\\\tan^{2}t$$===r=\\\\tan^{2}t', '$$\\\\sqrt{-t}$$===\\\\sqrt{-t}', '\\\\left(1\\\\right)+\\\\left(11\\\\right)+\\\\left(111\\\\right)+\\\\left(112\\\\right)+\\\\left(123\\\\right)===(1)+(11)+(111)+(112)+(123)', '\\\\intx^3dx===\\\\intd^{3}x', '$$\\\\frac{\\\\lambda}{\\\\sqrt{g}}$$===\\\\frac{1}{\\\\sqrt{8}}', 'm=M_0+M_1+M_2\\\\pi(C-1)-2\\\\pi^2C-M_3(C+1)===M=M_{0}+M_{1}Y+M_{2}[I(I+1)-\\\\frac{1}{4}Y^{2}]-M_{3}S(S+1)', '0+8512m^2+3.923m-6.620===0.7851n^{2}+3.929n-6.620', '$$x\\\\frac{p(-x)}{(xp(x))^{2}}$$===x\\\\frac{P(-x)}{(xP(x))^{2}}', '\\\\sum_{a=1}^{4}c_a=2B+4F===\\\\sum\\\\limits_{a=1}^{4}C_{a}=2B+4F', '$$2^{p-5}-(\\\\frac{1}{2}-2^{p-5})=2^{p-4}-\\\\frac{1}{2}$$===2^{p-5}-(\\\\frac{1}{2}-2^{p-5})=2^{p-4}-\\\\frac{1}{2}', '\\\\begin{equation}\\nE_{0}=-\\\\lambda+4-\\\\frac{\\\\lambda}{4}-\\\\frac{\\\\lambda}{2}-\\\\frac{\\\\lambda}{8}=-\\\\frac{3}{4}\\n\\\\end{equation}===E_{0}=-1+4\\\\frac{1}{4}\\\\frac{1}{2}\\\\frac{1}{2}=-\\\\frac{3}{4}', '$$\\\\sqrt{s},\\\\sqrt{s-b},\\\\sqrt{s-a}$$===\\\\sqrt{s},\\\\sqrt{s-b},\\\\sqrt{s-a}', '$$-\\\\frac{3+z^{2}}{8}-\\\\frac{(3+z^{2})^{2}}{32}$$===-\\\\frac{3+z^{2}}{8}-\\\\frac{(3+z^{2})^{2}}{32}', 'j^2=-\\\\left(\\\\frac{m}{2}+1\\\\right)-\\\\left(\\\\frac{m}{2}+\\\\frac{1}{2}\\\\right)k^{-2}===j_{2}=-(\\\\frac{n}{2}+1)-(\\\\frac{m}{2}+\\\\frac{1}{2})b^{-2}', '$$y_{1}(x)\\\\overline{{{pg}}}x$$===y_{1}(x)\\\\logx', '$$\\\\begin{array}{l}{k+x}\\\\end{array}$$===k+x', '$$\\\\sum_{i}P_{i}=\\\\sum_{i}P_{i}^{2}=1$$===\\\\sum\\\\limits_{i}p_{i}=\\\\sum\\\\limits_{i}p_{i}^{2}=1', '\\\\sin\\\\theta=\\\\frac{119}{120}===\\\\sin\\\\theta=\\\\frac{119}{120}', '$$2.71\\\\ldots$$===2.71\\\\ldots', '$$3y^{2}=4x^{3}-g_{2}y^{2}x-g_{3}y^{3}$$===zy^{2}=4x^{3}-g_{2}z^{2}x-g_{3}z^{3}', '$$c<c_{c}$$===c<c_{cr}', '\\\\lambda=\\\\lambda_0=2+\\\\sqrt{3}===x=x_{0}=2+\\\\sqrt{3}', '$$c\\\\geq0$$===C\\\\geq0', 'E=\\\\sqrt{2}\\\\int_{-1}^{+1}df\\\\,V(f)===E=\\\\sqrt{2}\\\\int\\\\limits_{-1}^{+1}df\\\\sqrt{V(f)}', '$$\\\\frac{6}{\\\\sqrt{60}}$$===\\\\frac{6}{\\\\sqrt{60}}', '$$\\\\cos\\\\pi$$===\\\\coskx', '$$z=x^{2+2}+ix^{2+3}$$===z=x^{2i+2}+ix^{2i+3}', '$$x^{\\\\prime}y^{\\\\prime}=qy^{\\\\prime}x^{\\\\prime}$$===x^{1}y^{1}=qy^{1}x^{1}', '<start_latex>\\n$$2^{22}$$\\n</end_latex>===2^{22}', 'a=n+\\\\frac{1}{2})n+\\\\frac{5}{6}===a=n+\\\\frac{1}{2},n+\\\\frac{5}{6}', '$$A=\\\\sum_{a}A^{a}t^{a}$$===A=\\\\sum\\\\limits_{a}A^{a}t^{a}', '$$z=\\\\frac{-b}{a}$$===z=\\\\frac{-b}{a}', '$$x_{0}+g(x-x_{0})$$===x_{0}+g(x-x_{0})', '$$\\\\frac{777}{400}$$===\\\\frac{777}{400}', '$$-\\\\frac{11-3+5B^{2}+B^{3}}{16}$$===-\\\\frac{11-z+5z^{2}+z^{3}}{16}', '$$\\\\sin\\\\theta_{1}\\\\sin\\\\theta_{2}\\\\sin\\\\theta_{3}$$===\\\\sin\\\\theta_{1}\\\\sin\\\\theta_{2}\\\\sin\\\\theta_{3}\\\\sin\\\\theta_{4}', '$$\\\\operatorname*{lim}_{d\\\\rightarrow\\\\infty}(R_{ab}-{\\\\frac{1}{2}}Rg_{ab})/(Cd-2)$$===\\\\lim\\\\limits_{d\\\\rightarrow2}(R_{ab}-\\\\frac{1}{2}Rg_{ab})/(d-2)', '$$-\\\\frac13\\\\intA^{3}$$===-\\\\frac{1}{3}\\\\intA^{3}', '$$x_{1}^{2}+x_{2}^{2}+x_{3}^{2}=1$$===x_{1}^{2}+x_{2}^{2}+x_{3}^{2}=1', 'b^{2}=7+\\\\frac{u^{2}}{2}=\\\\frac{1}{E^{2}}===b^{2}=1+\\\\frac{u^{2}}{2}=\\\\frac{1}{E^{2}}', '$$\\\\sin\\\\theta_{1}\\\\sin\\\\theta_{2}\\\\sin\\\\theta_{3}$$===\\\\sin\\\\theta_{1}\\\\sin\\\\theta_{2}\\\\sin\\\\theta_{3}', '$$\\\\frac{n\\\\left(2n-1\\\\right)\\\\left(2n+1\\\\right)}{3}$$===\\\\frac{n(2n-1)(2n+1)}{3}', '$$2\\\\intR_{ab}R^{b}c$$===2\\\\intR_{ab}R^{ab}c', '\\\\int_{0}^{1}x\\\\,dx=\\\\frac{1}{2}===\\\\intd^{4}x\\\\sqrt{g}', '$$\\\\pi=\\\\sqrt{n_{g}^{a}n_{g}^{a}}$$===r=\\\\sqrt{y^{a}y^{a}}', '$$\\\\int\\\\left(p+1\\\\right)$$===\\\\intC^{(p+1)}', '$$\\\\sum_{n}\\\\inK_{n},\\\\sum_{m}\\\\inK_{m}$$===\\\\sumn_{\\\\alpha}\\\\leqn,\\\\summ_{\\\\alpha}\\\\leqm', '$$\\\\frac{n-2}{n}\\\\left[\\\\frac{B(1-n)}{C(3n-4)}\\\\right]^{\\\\frac{n-2}{2n}}$$===2^{\\\\frac{n-2}{n}}[\\\\frac{B(1-n)}{C(3n-4)}]^{\\\\frac{n-2}{2n}}', '$$\\\\sqrt{\\\\delta_{y}}$$===\\\\sqrt{g_{yy}}', '\\\\sin^2x=\\\\frac{1}{2}(1-\\\\cos(2x))===\\\\sin^{2}x=\\\\frac{1}{2}(1-\\\\cos(2x))', '<start_latex>\\n$$c\\\\timesc$$\\n<end_latex>===C\\\\timesC', '\\\\int1\\\\,dx===\\\\intdX', '$$\\\\begin{array}{l}{j\\\\ge3}\\\\end{array}$$===j\\\\geq3', '$$\\\\log(-x)=\\\\log(x)+i\\\\pi$$===\\\\log(-x)=\\\\log(x)+i\\\\pi', '$$r=\\\\sqrt{(x^{1})^{2}+(x^{2})^{2}}$$===r=\\\\sqrt{(x^{1})^{2}+(x^{2})^{2}}', '$$T=\\\\operatorname*{lim}_{v\\\\rightarrow\\\\infty}u^{3}$$===T=\\\\lim\\\\limits_{u\\\\rightarrow\\\\infty}uz', '$$q_{yx}$$===qyx', 'x^{14}+x^{12}+x^{24}=C===X^{11}+X^{12}+X^{21}=C', '$$\\\\begin{array}{l}{S^{2}\\\\timesS^{2}\\\\timesS^{4}\\\\timesS^{2}}\\\\end{array}$$===S^{2}\\\\timesS^{2}\\\\timesS^{2}\\\\timesS^{2}', '$$\\\\frac{-4}{\\\\sqrt{60}}$$===\\\\frac{-4}{\\\\sqrt{60}}', '$$\\\\intdA$$===\\\\intdA', '$$\\\\frac{2\\\\pi}{\\\\beta}\\\\left(n+\\\\frac{1}{2}\\\\right)$$===\\\\frac{2\\\\pi}{\\\\beta}(n+\\\\frac{1}{2})', '\\\\int_{x}^{y}c_i===\\\\int\\\\limits_{x}^{y}c_{i}', '$$f(x)=(x_{a}^{2}-x_{b}^{2})$$===f(x)=(x_{a}^{2}-x_{b}^{2})', '\\\\lim_{y\\\\to\\\\infty}u(y)=5===\\\\lim\\\\limits_{y\\\\rightarrow\\\\infty}u(y)=s', '$$y=\\\\sqrt{y_{i}y_{j}}$$===y=\\\\sqrt{y_{i}y^{i}}', '$$F(x)=x\\\\left(1+\\\\frac{x}{a}\\\\right)$$===F(x)=x(1+\\\\frac{x}{a})', '$$\\\\left(\\\\frac{1}{3}+\\\\frac{5}{2x^{2}n^{2}}\\\\right)$$===(\\\\frac{1}{3}+\\\\frac{5}{2\\\\pi^{2}n^{2}})', '\\\\lim_{t\\\\to\\\\infty}|r(t)|=\\\\infty===\\\\lim\\\\limits_{t\\\\rightarrow\\\\infty}|\\\\gamma(t)|=\\\\infty', '$$\\\\frac{i}{k+i}=1-\\\\frac{k}{k+i}$$===\\\\frac{i}{k+i}=1-\\\\frac{k}{k+i}', 'h_{xx}=-h_{yy}===h_{xx}=-h_{yy}', '$$\\\\log\\\\left(x^{2}+y^{2}\\\\right)$$===\\\\log(x^{2}+y^{2})', '$$\\\\frac{m}{\\\\sqrt{2}}$$===\\\\frac{m}{\\\\sqrt{2}}', '1.0737+1.2227===1.0737+1.2227', '$$g(x)=\\\\beta_{ab}2^{a}x^{b}$$===g(x)=\\\\beta_{ab}x^{a}x^{b}', '$$z=\\\\intdy\\\\bar{a}^{-1}(y)$$===z=\\\\intdya^{-1}(y)', '$$-9.9599$$===-9.9599', '<start_latex>\\n\\\\documentclass{article}\\n\\\\usepackage{amsmath}\\n\\n\\\\begin{document}\\n\\n\\\\[\\\\tan\\\\theta/2\\\\]\\n\\n\\\\end{document}\\n</end_latex>===\\\\tan\\\\theta/2', 'n!\\\\binom{m}{n}(z)=(-z)^{n-m}m!\\\\binom{n-m}{m}(z)===n!L_{n}^{(m-n)}(z)=(-z)^{n-m}m!L_{m}^{(n-m)}(z)', '$$\\\\langlek\\\\rangle=x$$===t>x', '\\\\cosz_0===\\\\cosz_{0}', '$$F=\\\\frac{1}{4}F_{ab}F^{ab}$$===F=\\\\frac{1}{4}F_{ab}F^{ab}', '$$x^{3}x^{4}x^{5}$$===x^{3}x^{4}x^{5}', '$$x^{m}-ax^{4}+b=0$$===x^{n}-ax^{s}+b=0', '$$X=0.1,0.2\\\\ldots$$===X=0.1,0.2\\\\ldots', 'x_{0}dy=q_{1}dx+(q_{1}^{2}-1)dx===xdy=qdyx+(q^{2}-1)dxy', 'a=\\\\sqrt{\\\\frac{\\\\beta}{\\\\alpha}}===a=\\\\sqrt{\\\\frac{\\\\beta}{\\\\alpha}}', '$$\\\\frac{149}{84}$$===\\\\frac{149}{84}', '\\\\left(\\\\lambda_{1}-\\\\frac{\\\\lambda}{3},-\\\\frac{\\\\lambda}{3}\\\\right)-\\\\frac{\\\\lambda}{3}===(1,-\\\\frac{1}{3},-\\\\frac{1}{3},-\\\\frac{1}{3})', '$$\\\\frac{n}{2}+\\\\frac{7}{2}$$===\\\\frac{n}{2}+\\\\frac{7}{2}', '$$\\\\frac{3+z^{2}}{8}+\\\\frac{(3+z^{2})^{2}}{32}$$===\\\\frac{3+z^{2}}{8}+\\\\frac{(3+z^{2})^{2}}{32}', '$$\\\\frac{g}{2}$$===\\\\frac{9}{2}', '$$\\\\sumq_{i}=-\\\\frac{1}{4}$$===\\\\sumq_{i}=-\\\\frac{1}{4}', '$$\\\\left(\\\\frac{p^{2}-p}{1+p}-1\\\\right)$$===(\\\\frac{p2^{-p}}{1+p}-1)', '$$x^{2}+y^{5}+z^{3}$$===x^{2}+y^{5}+z^{3}', 'a=3\\\\left(4-\\\\sqrt{10}\\\\right)\\\\sqrt{10}/\\\\left(14\\\\sqrt{10}-5\\\\right)===a=3(4-\\\\sqrt{10})\\\\sqrt{10}/(14\\\\sqrt{10}-5)', '$$\\\\left(\\\\lambda_{2}S\\\\right)-\\\\left(\\\\lambda_{1}S\\\\right)+\\\\left(\\\\gamma_{3}S\\\\right)-\\\\left(\\\\gamma_{2}S\\\\right)-\\\\left(\\\\beta_{4}S\\\\right)-\\\\left(\\\\beta_{3}S\\\\right)$$===(125)-(135)+(735)-(725)-(1246)-(73)', 'a\\\\neq-b===a\\\\neq-b', '2f-e_1-e_3+2e_5+e_7+2e_9===2f-e_{1}-e_{3}+2e_{6}+e_{7}+2e_{9}', '8\\\\cos\\\\theta===8\\\\cos\\\\theta', '$$\\\\summ_{g}^{2}-\\\\summ_{f}^{1}=0$$===\\\\summ_{B}^{2}-\\\\summ_{F}^{2}=0', '<start_latex>\\n$$25^{\\\\sqrt[[objectObject]]{2^{-21}3^{8}}}$$\\n</end_latex>===25\\\\sqrt[5]{2^{-21}3^{8}}', '\\\\cos\\\\left[-\\\\frac{m}{2}\\\\sigma\\\\right]===\\\\tan[\\\\frac{n}{2}\\\\sigma]', '$$\\\\limy$$===\\\\limy', '\\\\alpha=\\\\frac{1}{\\\\tan\\\\theta}===\\\\alpha=\\\\frac{1}{\\\\tan\\\\theta}', '$$\\\\int_{\\\\mathbb{R}^{n}}$$===\\\\intR^{n}', '$$\\\\frac{325}{66}$$===\\\\frac{325}{66}', '$$\\\\frac{-4}{\\\\sqrt{360}}$$===\\\\frac{-4}{\\\\sqrt{360}}', '$$-\\\\frac{1}{2}<a+\\\\frac{1}{2}<0$$===-\\\\frac{1}{2}<a+\\\\frac{1}{2}<0', '\\\\left(ab\\\\right)=\\\\frac{1}{2}\\\\left(ab+ba\\\\right)===(ab)=\\\\frac{1}{2}(ab+ba)', '$$\\\\rho_{\\\\operatorname*{max}}={\\\\frac{8{\\\\sqrt{3}}}{15}}=0,924$$===P_{max}=\\\\frac{8\\\\sqrt{3}}{15}=0,924', '\\\\sigma(\\\\omega)=\\\\sum_{n}C_n\\\\omega^{n+1}===c(w)=\\\\sum\\\\limits_{n}c_{n}w^{-n+1}', '$$C=\\\\frac{1}{32}+\\\\frac{1}{96}\\\\log2$$===C=\\\\frac{1}{32}+\\\\frac{1}{96}\\\\log2', '-\\\\alpha_{p}-1+2\\\\alpha_{p}-\\\\alpha_{p+1}+X=0===-a_{p-1}+2a_{p}-a_{p+1}+X=0', '$$\\\\int^{ab}=da^{ab}+a^{ac}q^{ab}$$===f^{ab}=da^{ab}+a^{ac}a^{cb}', '$$-\\\\sqrt{b}$$===-\\\\intbB', '$$x^{n-1}+xy^{2}+z^{2}$$===x^{n-1}+xy^{2}+z^{2}', '$$f(y)=y^{\\\\frac{1}{n-2}}$$===f(y)=y^{\\\\frac{1}{n-2}}', '$$b_{c}=\\\\frac{1}{2}\\\\log(\\\\sqrt{2}+1)$$===b_{c}=\\\\frac{1}{2}\\\\log(\\\\sqrt{2}+1)', '$$\\\\frac{1}{c}$$===\\\\frac{1}{c}', '$$E\\\\frac{(m-p-1)}{m-p-2}_{n,p}$$===t_{n-p-2a_{p}}^{(n-p-1)}', 'xy=yx===xy=yx', '$$T(x)=iu\\\\sin(x)$$===T(x)=iu\\\\sin(x)', '$$\\\\tau=\\\\frac{x^{0}-x^{9}}{2}$$===v=\\\\frac{x^{0}-x^{9}}{2}', '$$\\\\left(\\\\begin{array}{ll}{1&1\\\\\\\\2&2}\\\\end{array}\\\\right)\\\\left(\\\\begin{array}{ll}{0&0\\\\\\\\0&0}\\\\end{array}\\\\right)$$===(\\\\frac{1}{2}\\\\frac{1}{2}\\\\frac{1}{2}\\\\frac{1}{2}0000)', '$$\\\\sqrt{kx}$$===k\\\\timesx', '$$x-5\\\\frac{6}{10}=2$$===x\\\\div5\\\\div2', '$$\\\\int_{-m}^{n}d^{4}x$$===\\\\int\\\\limits_{-n}^{n}d^{4}x', '\\\\lim_{x\\\\to\\\\pm\\\\infty}P\\\\left(\\\\frac{e^{ikx}}{k}\\\\right)===\\\\lim\\\\limits_{x\\\\rightarrow\\\\pm\\\\infty}P(\\\\frac{e^{ikx}}{k})', '$$A=\\\\frac{4Bx^{2}\\\\sqrt{1-x}}{\\\\sqrt{1+3x}}-4(8+\\\\log(4))$$===b-\\\\frac{4B\\\\pi^{2}\\\\sqrt{1-x}}{\\\\sqrt{1+3x}}-4(\\\\gamma+\\\\log(4))', 'f_{n-1}(x)=b_{n-n}x^{n-1}+\\\\ldots+b_0===f_{n-1}(x)=b_{n-1}x^{n-1}+\\\\ldots+b_{0}', '<start_latex>\\n$$\\\\sqrt{\\\\cos(x)}$$\\n<end_latex>===\\\\sqrt[c]{\\\\cos(x)}', '<start_latex>\\n$$\\\\sqrt{1+t}$$\\n<end_latex>===\\\\sqrt{1+t}', '\\\\sin(n\\\\pi)===\\\\sin(nv)', '\\\\lambda=\\\\frac{\\\\lambda_2}{\\\\lambda_1-1}=\\\\frac{\\\\lambda_3}{\\\\lambda_1-1}===n=\\\\frac{n_{2}}{n_{1}-1}=\\\\frac{n_{3}}{n_{1}-1}', '$$\\\\sqrt{\\\\frac{k}{n}}$$===\\\\sqrt{\\\\frac{k}{n}}', '$$\\\\int_{0}^{d}xe(x)$$===\\\\intd^{d}xe(x)', '$$q_{c}(t)=Sim\\\\left(Ht\\\\right)$$===a(t)=\\\\sin(Ht)', '$$\\\\beta=\\\\sqrt{2}\\\\alphaf$$===\\\\beta=\\\\sqrt{2ab}', '$$H=\\\\sqrt{\\\\frac52}\\\\left(\\\\frac1{(x-1)}+\\\\frac12\\\\right)$$===H=\\\\sqrt{\\\\frac{5}{2}}(\\\\frac{1}{(x-1)}+\\\\frac{1}{2})', '\\\\cos(u)===\\\\cos(v)', '\\\\sin(\\\\theta)\\\\neq0===\\\\sin(\\\\theta)\\\\neq0', '\\\\sin(\\\\theta)===\\\\sin(\\\\theta)', '$$\\\\left(1-x\\\\right)^{c-a-b}$$===(1-x)^{c-a-b}']\n",
      "Average BLEU score: 0.5541\n",
      "--------------------------------------------------Computing ExpRate--------------------------------------------------\n",
      "ExpRate: 5.56%\n",
      "ExpRate (<=1 error): 7.22%\n",
      "ExpRate (<=2 errors): 7.22%\n",
      "\u001b[1m\u001b[33mswanlab\u001b[0m\u001b[0m: List length 'Prediction' is too long, cut to 108.\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: üåü Run `\u001b[1mswanlab watch /root/autodl-tmp/HOCR/finetune/swanlog\u001b[0m` to view SwanLab Experiment Dashboard locally\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: üè† View project at \u001b[34m\u001b[4mhttps://swanlab.cn/@Wonster/Qwen2.5-VL-7b-finetune-with-test\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://swanlab.cn/@Wonster/Qwen2.5-VL-7b-finetune-with-test/runs/oxj92mh6897rqo10054nr\u001b[0m\u001b[0m\n",
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "swan_list = test_results(test_dataset, val_peft_model, return_list=True)  # Ê≤°Êúâ swanlab, return_list=False\n",
    "if swan_list is not None:\n",
    "    swanlab.log({\"Prediction\": swan_list})\n",
    "    # Âú® Jupyter Notebook ‰∏≠ËøêË°åÊó∂Ë¶ÅÂÅúÊ≠¢SwanLabËÆ∞ÂΩï ÈúÄË¶ÅË∞ÉÁî®swanlab.finish()\n",
    "    swanlab.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
