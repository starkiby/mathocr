{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-22T11:39:57.201810Z",
     "start_time": "2025-03-22T11:39:53.518403Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from operator import index\n",
    "import polars as pl\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from unsloth import FastVisionModel\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import pyarrow.parquet as pq"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hh/anaconda3/envs/mocr/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:39:57.207034Z",
     "start_time": "2025-03-22T11:39:57.204659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ],
   "id": "cc27fe2a43306799",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:39:57.275070Z",
     "start_time": "2025-03-22T11:39:57.273311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# datsaet path\n",
    "DATASET_PATH = '/home/hh/math ocr/unified_dataset/unified_math_ocr_dataset.parquet'\n",
    "OUTPUT_DIR = '/home/hh/math ocr/model_outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ],
   "id": "a727520a90d62354",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:39:57.320191Z",
     "start_time": "2025-03-22T11:39:57.318385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# min_size=28\n",
    "def bytes_to_image(byte_data):\n",
    "    \"\"\"Convert bytes to a PIL image object.\"\"\"\n",
    "    img = Image.open(io.BytesIO(byte_data))\n",
    "    # width, height = img.size\n",
    "    # if width < min_size or height < min_size:\n",
    "    #     # Maintain aspect ratio while ensuring minimum dimensions\n",
    "    #     new_width = max(min_size, width)\n",
    "    #     new_height = max(min_size, height)\n",
    "    #\n",
    "    #     # Resize the image\n",
    "    #     img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "    # weight and height should be multiples of 28\n",
    "    return img.resize((140, 210), Image.Resampling.LANCZOS)"
   ],
   "id": "1d9f9c8aa42b821d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:40:00.736872Z",
     "start_time": "2025-03-22T11:39:57.362284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Load and prepare the dataset.\"\"\"\n",
    "logger.info(\"load dataset...\")\n",
    "# parquet_file = pq.ParquetFile(DATASET_PATH)\n",
    "# for i in range(parquet_file.num_row_groups):\n",
    "#     df = parquet_file.read_row_group(i).to_pandas()\n",
    "dl = pl.read_parquet(DATASET_PATH)\n",
    "df= dl.to_pandas()\n",
    "# df = pd.read_parquet(DATASET_PATH)\n",
    "logger.info(f\"The dataset has been successfully loadedÔºåThere are {len(df)} records in total.\")"
   ],
   "id": "9c3390e4d5c81ce6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 22:39:57,363 - INFO - load dataset...\n",
      "2025-03-22 22:40:00,735 - INFO - The dataset has been successfully loadedÔºåThere are 197024 records in total.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:40:00.748564Z",
     "start_time": "2025-03-22T11:40:00.744709Z"
    }
   },
   "cell_type": "code",
   "source": "df.iloc[3]",
   "id": "9750576ad223a4e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image    {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...\n",
       "text     N H _ { 4 } C l + N a O H = N a C l + H _ { 2 ...\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:40:00.796167Z",
     "start_time": "2025-03-22T11:40:00.793861Z"
    }
   },
   "cell_type": "code",
   "source": "print(df.iloc[3]['text'])",
   "id": "9b5a6d93767167d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N H _ { 4 } C l + N a O H = N a C l + H _ { 2 } O + N H _ { 3 } \\uparrow\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:42:06.954271Z",
     "start_time": "2025-03-22T11:40:00.812201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the dataset into the format required for fine-tuning.\n",
    "converted_dataset = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"convert dataset\"):\n",
    "    img = bytes_to_image(row['image']['bytes'])\n",
    "    latex_code = row['text']\n",
    "\n",
    "    # Create the converted data format\n",
    "    conversation = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Write the LaTeX representation for this image.\"},\n",
    "                    {\"type\": \"image\", \"image\": img}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": latex_code}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    converted_dataset.append(conversation)"
   ],
   "id": "55705aae4356faac",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197024/197024 [02:06<00:00, 1561.96it/s]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:42:06.983025Z",
     "start_time": "2025-03-22T11:42:06.981214Z"
    }
   },
   "cell_type": "code",
   "source": "converted_dataset[3]",
   "id": "6a7af5afeafbce96",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'Write the LaTeX representation for this image.'},\n",
       "    {'type': 'image', 'image': <PIL.Image.Image image mode=L size=140x210>}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'N H _ { 4 } C l + N a O H = N a C l + H _ { 2 } O + N H _ { 3 } \\\\uparrow'}]}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:42:07.027106Z",
     "start_time": "2025-03-22T11:42:07.023001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split training set and test set (8:2)\n",
    "train_size = int(len(converted_dataset) * 0.8)\n",
    "train_dataset = converted_dataset[:train_size]\n",
    "val_dataset = converted_dataset[train_size:]\n",
    "\n",
    "logger.info(f\"training set size: {len(train_dataset)}\")\n",
    "logger.info(f\"validation set size: {len(val_dataset)}\")"
   ],
   "id": "6bf9fe571c5c6f3a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 22:42:07,025 - INFO - training set size: 157619\n",
      "2025-03-22 22:42:07,026 - INFO - validation set size: 39405\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:42:07.076428Z",
     "start_time": "2025-03-22T11:42:07.073830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger.info(\"Start fine-tuning the Qwen2.5 Vision model...\")\n",
    "# Ê£ÄÊü•CUDAÊòØÂê¶ÂèØÁî®\n",
    "if not torch.cuda.is_available():\n",
    "    logger.error(\"CUDA is not available. Please ensure that your graphics card and drivers are properly configured.\")\n",
    "\n",
    "logger.info(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "logger.info(f\"CUDA Version: {torch.version.cuda}\")\n"
   ],
   "id": "38035d32025af361",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 22:42:07,074 - INFO - Start fine-tuning the Qwen2.5 Vision model...\n",
      "2025-03-22 22:42:07,075 - INFO - Using GPU: NVIDIA GeForce RTX 4090\n",
      "2025-03-22 22:42:07,075 - INFO - CUDA Version: 12.4\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:42:36.111890Z",
     "start_time": "2025-03-22T11:42:07.118807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Âä†ËΩΩÊ®°Âûã\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-VL-3B-Instruct\",\n",
    "    load_in_4bit=True,  # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for long context\n",
    ")"
   ],
   "id": "a365b6eb321a6eb2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.17: Fast Qwen2 patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.617 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:42:39.331163Z",
     "start_time": "2025-03-22T11:42:36.343105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = True, # False if not finetuning vision layers\n",
    "    finetune_language_layers   = True, # False if not finetuning language layers\n",
    "    finetune_attention_modules = True, # False if not finetuning attention layers\n",
    "    finetune_mlp_modules       = True, # False if not finetuning MLP layers\n",
    "\n",
    "    r = 32,           # The larger, the higher the accuracy, but might overfit\n",
    "    lora_alpha = 16,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    "    # target_modules = \"all-linear\", # Optional now! Can specify a list if needed\n",
    ")"
   ],
   "id": "564a09ddfb3c3065",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:42:39.619585Z",
     "start_time": "2025-03-22T11:42:39.566863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from unsloth import is_bf16_supported\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "FastVisionModel.for_training(model) # Enable for training!\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = UnslothVisionDataCollator(model, tokenizer), # Must use!\n",
    "    train_dataset = converted_dataset,\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 100,\n",
    "        # num_train_epochs = 1, # Set this instead of max_steps for full training runs\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bf16_supported(),\n",
    "        bf16 = is_bf16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\",     # For Weights and Biases\n",
    "\n",
    "        # You MUST put the below items for vision finetuning:\n",
    "        remove_unused_columns = False,\n",
    "        dataset_text_field = \"\",\n",
    "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
    "        dataset_num_proc = 4,\n",
    "        max_seq_length = 4096,\n",
    "        greater_is_better=False,\n",
    "    ),\n",
    ")"
   ],
   "id": "b1f71fb7bbaafc1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Model does not have a default image size - using 512\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:42:39.853402Z",
     "start_time": "2025-03-22T11:42:39.851304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ],
   "id": "54e38379de521aa6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4090. Max memory = 23.617 GB.\n",
      "3.783 GB of memory reserved.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:44:35.359811Z",
     "start_time": "2025-03-22T11:42:40.082696Z"
    }
   },
   "cell_type": "code",
   "source": "trainer_stats = trainer.train()",
   "id": "84072a114172de6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 197,024 | Num Epochs = 1 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 82,169,856/3,000,000,000 (2.74% trained)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 01:36, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.898800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.944700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.977600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.166900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.783600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.209800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.053400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.697100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.280600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.062900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.907000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.709700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.549000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.571500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.405800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.331600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.450800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.370700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.478400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.458100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.412600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.399100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.235700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.230200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.354600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.321400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.472900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.125200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.386200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.251800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.428300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.304600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.405200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.274100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.225100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.251400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.479800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.293200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.349000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.254400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.212100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.390900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.368300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.331800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.176800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.182800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.335800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.303700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.394700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.260200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.248900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.385800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.291600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.187700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.204100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.195700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.304100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.264400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.313600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.349900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.460400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.337200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.192600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.362700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.234500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.301600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.412900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.459800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.228700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.396200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.489900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.268300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.233600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.353400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.301400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.377300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.312300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.225300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.332000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.287900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.319500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.295200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.248500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.470200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.300600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.288600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.345600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.334200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.366800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.296500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:44:35.788438Z",
     "start_time": "2025-03-22T11:44:35.785900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ],
   "id": "da2518d9dfc73ab5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.1113 seconds used for training.\n",
      "1.9 minutes used for training.\n",
      "Peak reserved memory = 4.396 GB.\n",
      "Peak reserved memory for training = 0.613 GB.\n",
      "Peak reserved memory % of max memory = 18.614 %.\n",
      "Peak reserved memory for training % of max memory = 2.596 %.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "FastVisionModel.for_inference(model) # Enable for inference!\n",
    "image = Image.open('/home/hh/math ocr/MLHME38K/train_images/train_5.jpg').resize((140, 210), Image.Resampling.LANCZOS)\n",
    "instruction = r'''You are an AI assistant specialized in converting PDF images to Markdown format. Please follow these instructions for the conversion:\n",
    "\n",
    "        1. Text Processing:\n",
    "        - Accurately recognize all text content in the PDF image without guessing or inferring.\n",
    "        - Convert the recognized text into Markdown format.\n",
    "        - Maintain the original document structure, including headings, paragraphs, lists, etc.\n",
    "\n",
    "        2. Mathematical Formula Processing:\n",
    "        - Convert all mathematical formulas to LaTeX format.\n",
    "        - Enclose inline formulas with \\( \\). For example: This is an inline formula \\( E = mc^2 \\)\n",
    "        - Enclose block formulas with \\\\[ \\\\]. For example: \\[ \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} \\]\n",
    "\n",
    "        3. Table Processing:\n",
    "        - Convert tables to HTML format.\n",
    "        - Wrap the entire table with <table> and </table>.\n",
    "\n",
    "        4. Figure Handling:\n",
    "        - Ignore figures content in the PDF image. Do not attempt to describe or convert images.\n",
    "\n",
    "        5. Output Format:\n",
    "        - Ensure the output Markdown document has a clear structure with appropriate line breaks between elements.\n",
    "        - For complex layouts, try to maintain the original document's structure and format as closely as possible.\n",
    "\n",
    "        Please strictly follow these guidelines to ensure accuracy and consistency in the conversion. Your task is to accurately convert the content of the PDF image into Markdown format without adding any extra explanations or comments.\n",
    "        '''\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": instruction}\n",
    "    ]}\n",
    "]\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens = False,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 1024,\n",
    "                   use_cache = True, temperature = 1.0, min_p = 0.1)"
   ],
   "id": "4c0e61669e5e23cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:45:17.257338Z",
     "start_time": "2025-03-22T11:45:17.256045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.save_pretrained(\"test_model\") # Local saving\n",
    "tokenizer.save_pretrained(\"test_model\")"
   ],
   "id": "ba0a275ac5d25fd7",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# doing quantization for the model, then we can use it in ollama platform\n",
    "model.save_pretrained_gguf(\"model_path\", tokenizer,)"
   ],
   "id": "1891803ab21c4329",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5f49dc3640dcdcbc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
